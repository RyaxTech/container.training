---

# Notre application sample

- Nous allons cloner le d√©p√¥t GitHub sur notre 1er noeud

- Le r√©f√©rentiel contient √©galement des scripts et des outils que nous utiliserons √† travers l'atelier

.exercise[

- Cloner le d√©p√¥t sur `node1`:
  ```bash
  git clone https://github.com/RyaxTech/kube.training 
  ```

]

(Vous pouvez √©galement faire un fork du d√©p√¥t sur GitHub et cloner votre fork si vous pr√©f√©rez cela.)

---

## T√©l√©chargement et ex√©cution de l'application

Commen√ßons la procedure, car le t√©l√©chargement prendra un peu de temps ...

.exercise[

- Allez dans le r√©pertoire `dockercoins`, dans le repo clone:
  ```bash
  cd ~/kube.training/dockercoins
  ```

- Utilisez Compose pour g√©n√©rer et ex√©cuter tous les conteneurs:
  ```bash
  docker-compose up
  ``` 
]

Compose dit √† Docker de construire toutes les images du conteneur (en tirant
les images de base correspondantes), puis d√©marre tous les conteneurs,
et affiche les logs agr√©g√©s.

---

## Plus de d√©tails sur notre exemple d'application

- Visitez le lien GitHub avec tous les mat√©riaux de cet atelier:
  <br/> https://github.com/RyaxTech/kube.training

- L'application est dans le sous-r√©pertoire [dockercoins](https://github.com/RyaxTech/kube.training/tree/master/dockercoins)

- Regardons la disposition g√©n√©rale du code source:

  il y a un fichier Compose [docker-compose.yml](https://github.com/RyaxTech/kube.training/blob/master/dockercoins/docker-compose.yml) ...

  ... et 4 autres services, chacun dans son propre r√©pertoire:

  - `rng` = service web g√©n√©rant des octets al√©atoires
  - `hasher` = hachage informatique du service Web des donn√©es POSTed
  - `worker` = processus de fond utilisant `rng` et `hasher`
  - `webui` = interface web pour suivre les progr√®s

---

## D√©couverte de service dans le terrain de conteneurs

- Nous ne codons pas les adresses IP dans le code

- Nous ne codons pas le nom de domaine complet dans le code, soit

- Nous nous connectons simplement √† un nom de service, et la magie des conteneurs fait le reste

  (Et par magie des conteneurs, nous entendons "un serveur DNS dynamique et embarqu√©")

---

## Exemple dans `worker/worker.py`

```python
redis = Redis("`redis`")


def get_random_bytes():
    r = requests.get ("http://`rng`/32")
    return r.content


def hash_bytes(data):
    r = requests.post("http://`hasher`/",
                      data = data,
                      headers = {"Content-Type": "application/octet-stream"})
```

(Code source complet disponible [ici](
https://github.com/RyaxTech/kube.training/blob/8279a3bce9398f7c1a53bdd95187c53eda4e6435/dockercoins/worker/worker.py#L17
))

---

class: extra-details

## Liens, d√©nomination et d√©couverte de service

- Les conteneurs peuvent avoir des alias r√©seau (r√©solvables via DNS)

- Compose le fichier version 2+ rend chaque conteneur accessible via son nom de service

- Compose la version 1 du fichier a n√©cessit√© des sections "liens"

- Les alias r√©seau sont automatiquement "namespaced"

  - vous pouvez avoir plusieurs applications d√©clarant et utilisant un service nomm√© `database`

  - les conteneurs dans l'application bleue vont r√©soudre `database` √† l'adresse IP de la base de donn√©es bleue

  - les conteneurs dans l'application verte vont r√©soudre `base de donn√©es` √† l'adresse IP de la base de donn√©es verte

---

## Qu'est-ce qu'elle fait cette application?

--

- C'est un mineur de DockerCoin! .emoji[üí∞üê≥üì¶üö¢]

--

- Non, vous ne pouvez pas acheter de caf√© avec DockerCoins

--

- Comment fonctionne DockerCoins:

  - `worker` demande √† `rng` de g√©n√©rer quelques octets al√©atoires

  - `worker` nourrit ces octets en `hasher`

  - et r√©p√®te pour toujours!

  - chaque seconde, `worker` met √† jour `redis` pour indiquer combien de boucles ont √©t√© faites

  - `webui` interroge `redis`, et calcule et expose la "vitesse de hachage" dans votre navigateur

---

## Notre application au travail

- Sur le c√¥t√© gauche, la "rainbow strip" montre les noms des conteneurs

- Sur le c√¥t√© droit, nous voyons la sortie de nos conteneurs

- Nous pouvons voir le service `worker` faire des requ√™tes √† `rng` et `hasher`

- Pour `rng` et `hasher`, nous voyons les logs d'acc√®s HTTP

---

## Connexion √† l'interface Web

- Le conteneur `webui` expose un dashboard Web; Voyons voir

.exercise[

- Avec un navigateur Web, connectez-vous √† `node1` sur le port 8000

- Rappel: les alias `nodeX` ne sont valables que sur les n≈ìuds eux-m√™mes

- Dans votre navigateur, vous devez entrer l'adresse IP de votre noeud

]

Une zone de dessin devrait appara√Ætre, et apr√®s quelques secondes, un graphique bleu appara√Ætra.

---

class: extra-details

## Pourquoi la vitesse semble-t-elle irr√©guli√®re?

- On *dirait que* la vitesse est d'environ 4 hashes/seconde

- Ou plus pr√©cis√©ment: 4 hashes/seconde, avec des creux r√©guliers jusqu'√† z√©ro

- Pourquoi?

--

class: extra-details

- L'application a en fait une vitesse constante et constante: 3,33 hachages / seconde
  <br/>
  (ce qui correspond √† 1 hash toutes les 0.3 secondes)

- Oui et?

---

class: extra-details

## La raison pour laquelle ce graphique n'est *pas g√©nial*

- Le "worker" ne met pas √† jour le compteur apr√®s chaque boucle, mais jusqu'√† une fois par seconde

- La vitesse est calcul√©e par le navigateur, v√©rifiant le compteur environ une fois par seconde

- Entre deux mises √† jour cons√©cutives, le compteur augmentera de 4 ou de 0

- La vitesse per√ßue sera donc 4 - 4 - 4 - 0 - 4 - 4 - 0 etc.

---

## Arr√™t de l'application

- Si nous interrompons Compose (avec `^C`), il demandera poliment au Docker Engine d'arr√™ter l'application

- Le moteur Docker enverra un signal `TERM` aux conteneurs

- Si les conteneurs ne sortent pas en temps voulu, le moteur envoie un signal "KILL"

.exercise[

- Arr√™tez l'application en tapant `^C`

]

-

Certains conteneurs sortent imm√©diatement, d'autres prennent plus de temps.

Les conteneurs qui ne g√®rent pas `SIGTERM` finissent par √™tre d√©truits apr√®s un d√©lai de 10s. Si nous sommes tr√®s impatients, nous pouvons frapper `^C` une seconde fois!
