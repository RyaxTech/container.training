class: title

Notre application sur Kubernetes

---

## Qu'est-ce qu'il y'a au menu?

Dans cette partie, nous allons:

- **construire** des images pour notre application,

- **exp√©dier** ces images avec un registre,

- **d√©ployer** des d√©ploiements utilisant ces images,

- exposer ces d√©ploiements pour qu'ils puissent communiquer entre eux,

- exposer l'interface web afin que nous puissions y acc√©der de l'ext√©rieur.

---

## Le plan

- Construction sur notre noeud de contr√¥le (`node1`)

- Marquage des images pour qu'elles soient nomm√©es `$REGISTRY/servicename`

- T√©l√©chargement sur un registre

- Creation des d√©ploiements en utilisant les images

- Exposition (avec un ClusterIP) des services qui ont besoin de communiquer

- Exposition (avec un NodePort) de l'interface Web

---

## Quel registre voulons-nous utiliser?

- Nous pourrions utiliser le Docker Hub

- Ou un service offert par notre fournisseur de cloud (ACR, GCR, ECR ...)

- Ou nous pourrions simplement auto-h√©berger ce registre

*Nous h√©bergerons automatiquement le registre car c'est la solution la plus g√©n√©rique pour cet atelier.*

---

## Utiliser le registre open source

- Nous devons lancer un conteneur `registry:2`
  <br/>(assurez-vous de sp√©cifier la balise `:2` pour ex√©cuter la nouvelle version!)

- Il va stocker des images et des couches dans le syst√®me de fichiers local
  <br/>(mais vous pouvez ajouter un fichier de configuration pour utiliser S3, Swift, etc.)

- Docker *n√©cessite* TLS lors de la communication avec le registre

  - sauf pour les registres sur ¬´127.0.0.0/8¬ª (c'est-√†-dire `localhost`)

  - ou avec le flag Engine `--insecure-registry`

- Notre strat√©gie: publier le conteneur de registre sur un NodePort,
  <br/> pour qu'il soit disponible via `127.0.0.1:xxxxx` sur chaque noeud

---

# D√©ployer un registre auto-h√©berg√©

- Nous allons d√©ployer un conteneur de registre et l'exposer avec un NodePort

.exercise[

- Cr√©ez le service de registre:
  ```bash
  kubectl run registry --image=registry:2
  ```

- Exposez-le sur un NodePort:
  ```bash
  kubectl expose deploy/registry --port=5000 --type=NodePort
  ```

]

---

## Connexion √† notre registre

- Nous devons trouver quel port a √©t√© attribu√©

.exercise[

- Voir les d√©tails du service:
  ```bash
  kubectl describe svc/registry
  ```

- Obtenez le num√©ro de port par programme:
  ```bash
  NODEPORT=$(kubectl get svc/registry -o json | jq .spec.ports[0].nodePort)
  REGISTRY=127.0.0.1:$NODEPORT
  ```

]

---

## Test de notre registre

- Une route API de registre Docker pratique √† retenir est `/v2/_catalog`

.exercise[

- Voir les d√©p√¥ts actuellement d√©tenus dans notre registre:
  ```bash
  curl $REGISTRY/v2/_catalog
  ```

]

--

Nous devrions voir:
```json
{"repositories": []}
```

---

## Test de notre registre local

- Nous pouvons retagger une petite image, et la pousser vers le registre

.exercise[

- Assurez-vous que nous avons l'image busybox, et retaggez la:
  ```bash
  docker pull busybox
  docker tag busybox $REGISTRY/busybox
  ```

- Poussez-le:
  ```bash
  docker push $REGISTRY/busybox
  ```

]

---

## V√©rifier √† nouveau ce qu'il y a dans notre registre local

- Utilisons le m√™me point final que pr√©c√©demment

.exercise[

- Assurez-vous que notre image busybox est maintenant dans le registre local:
  ```bash
  curl $ REGISTRY / v2 / _catalog
  ```

]

La commande curl devrait maintenant sortir:
```json
{"repositories": ["busybox"]}
```

---

## Construire et pousser nos images

- Nous allons utiliser une fonctionnalit√© pratique de Docker Compose

.exercise[

- Allez dans le r√©pertoire `stacks`:
  ```bash
  cd ~/container.training/stacks
  ```

- Construire et pousser les images:
  ```bash
  export REGISTRY
  export TAG=v0.1
  docker-compose -f dockercoins.yml build
  docker-compose -f dockercoins.yml push
  ```

]

Jetons un coup d'≈ìil au fichier `dockercoins.yml` pendant que ce dernier construit et pousse.

---

```yaml
version: "3"

services:
  rng:
    build: dockercoins/rng
    image: ${REGISTRY-127.0.0.1:5000}/rng:${TAG-latest}
    deploy:
      mode: global
  ...
  redis:
    image: redis
  ...
  worker:
    build: dockercoins/worker
    image: ${REGISTRY-127.0.0.1:5000}/worker:${TAG-latest}
    ...
    deploy:
      replicas: 10
```

.warning[Juste au cas o√π vous vous poseriez la question ... Les "services" de Docker ne sont pas des "services" de Kubernetes.]

---

class: extra-details

## √âviter le tag `latest`

.warning[Assurez-vous d'avoir bien d√©fini la variable `TAG`!]

- Si vous ne le faites pas, le tag sera par d√©faut `latest`

- Le probl√®me avec `latest`: personne ne sait √† quoi √ßa veut dire!

  - Le dernier commit dans le repo?

  - Le dernier commit dans une branche? (Laquelle?)

  - Le dernier tag?

  - Une version al√©atoire pouss√©e par un membre de l'√©quipe al√©atoire?

- Si vous continuez √† appuyer sur la balise `latest`, comment faire de rollback?

- Les tags de "Images" doivent √™tre significatives, c'est-√†-dire correspondre √† des branches, tags, ou hashes

---

## D√©ploiement de toutes les choses

- Nous pouvons maintenant d√©ployer notre code (ainsi qu'une instance redis)

.exercise[

- D√©ployer `redis`:
  ```bash
  kubectl run redis --image=redis
  ```

- D√©ployer tout le reste:
  ```bash
   for SERVICE in hasher rng webui worker; do
      kubectl run $SERVICE --image=$REGISTRY/$SERVICE:$TAG
    done
  ```

]

---

## Est-ce que √ßa marche?

- Apr√®s avoir attendu la fin du d√©ploiement, regardons les logs!

  (Indice: utilisez `kubectl get deploy -w` pour regarder les √©v√©nements de d√©ploiement)

.exercise[

- Regardez quelques logs:
  ```bash
  kubectl logs deploy/rng
  kubectl logs deploy/worker
  ```

]

--

ü§î `rng` va bien ... Mais pas `worker`.

--

üí° Oh, c'est vrai! Nous avons oubli√© de "exposer".

---

# Exposant des services en interne

- Trois d√©ploiements doivent √™tre accessibles par d'autres: `hasher`,` redis`, `rng`

- `worker` n'a pas besoin d'√™tre expos√©

- `webui` sera trait√© plus tard

.exercise[

- Exposez chaque d√©ploiement, en sp√©cifiant le bon port:
  ```bash
  kubectl expose deployment redis --port 6379
  kubectl expose deployment rng --port 80
  kubectl expose deployment hasher --port 80
  ```

]

---

## Est-ce que √ßa marche encore?

- Le `worker` a une boucle infinie, qui r√©essaie 10 secondes apr√®s une erreur

.exercise[

- Diffuser les logs du worker:
  ```bash
  kubectl logs deploy/worker --follow
  ```

  (Donnez-lui environ 10 secondes pour r√©cup√©rer)

]

--

Nous devrions maintenant voir le ¬´travailleur¬ª, bien, travaillant heureusement.

---

# Exposant des services pour un acc√®s externe

- Maintenant, nous aimerions acc√©der √† l'interface Web

- Nous l'exposerons avec un `NodePort`

  (Juste comme nous l'avons fait pour le registre)

.exercise[

- Cr√©ez un service `NodePort` pour l'interface Web:
  ```bash
  kubectl expose deploy/webui --type=NodePort --port=8080
  ```

- V√©rifiez le port qui a √©t√© allou√©:
  ```bash
  kubectl obtenir svc
  ```

]

---

## Acc√®s √† l'interface utilisateur Web

- Nous pouvons maintenant nous connecter √† *n'importe quel noeud*, sur le port de noeud allou√©, pour voir l'interface web

.exercise[

- Ouvrez l'interface web dans votre navigateur (http://node-ip-address:3xxxx/)
]

--

*D'accord, nous sommes de retour l√† o√π nous avons commenc√©, quand nous utilisions un seul n≈ìud!*


